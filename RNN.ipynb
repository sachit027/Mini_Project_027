{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "95y1df3jTjqN"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JUrVeoLCTp1h"
   },
   "outputs": [],
   "source": [
    "# Function to extract features from audio files\n",
    "def extract_features(audio_file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file_path, sr=None)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        # Resize the feature matrix to a fixed size (e.g., 40x173)\n",
    "        resized_mfccs = np.resize(mfccs, (40, 173))  # You may adjust the size as needed\n",
    "        return resized_mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {audio_file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "D2XYclpZTp4Q"
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store features and labels\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Km1f8CS5Tp7w"
   },
   "outputs": [],
   "source": [
    "# Process healthy data\n",
    "healthy_data_path = 'C:/Users/rishi/Desktop/mini project-1/healthy'\n",
    "for file_name in os.listdir(healthy_data_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        audio_file_path = os.path.join(healthy_data_path, file_name)\n",
    "        features = extract_features(audio_file_path)\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            y.append(0)  # Label for healthy patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tYKkiGIbT3_g"
   },
   "outputs": [],
   "source": [
    "# Process unhealthy data\n",
    "unhealthy_data_path = 'C:/Users/rishi/Desktop/mini project-1/unhealthy'\n",
    "for file_name in os.listdir(unhealthy_data_path):\n",
    "    if file_name.endswith('.wav'):\n",
    "        audio_file_path = os.path.join(unhealthy_data_path, file_name)\n",
    "        features = extract_features(audio_file_path)\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            y.append(1)  # Label for unhealthy patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rWZMmqi-T4Co"
   },
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "I6FBB9BwT-jh"
   },
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mdyKIPY1T-mh"
   },
   "outputs": [],
   "source": [
    "# Reshape the input data for compatibility with LSTM layer\n",
    "# For LSTM, the input shape should be (num_samples, timesteps, input_dim)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LWBxP7tvT4F5"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Define the RNN model architecture (replace with your desired architecture if needed)\n",
    "model = keras.Sequential([\n",
    "  keras.layers.LSTM(64, return_sequences=True, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "  keras.layers.LSTM(32, activation='relu'),\n",
    "  keras.layers.Dense(16, activation='relu'),\n",
    "  keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sXxp_uLSTp-6"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RcMEhe5MUI-T"
   },
   "outputs": [],
   "source": [
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uExT40FqULWU",
    "outputId": "8f7ceee1-de92-48f5-9ba8-7980070a2fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5206 - loss: 146.8259 - val_accuracy: 0.5608 - val_loss: 327.6545\n",
      "Epoch 2/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4386 - loss: 185.4194 - val_accuracy: 0.4797 - val_loss: 90.3103\n",
      "Epoch 3/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5009 - loss: 80.0843 - val_accuracy: 0.4662 - val_loss: 99.5671\n",
      "Epoch 4/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 67.4738 - val_accuracy: 0.4662 - val_loss: 61.9652\n",
      "Epoch 5/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5388 - loss: 118.5476 - val_accuracy: 0.5473 - val_loss: 187.9367\n",
      "Epoch 6/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4518 - loss: 324.5692 - val_accuracy: 0.4730 - val_loss: 307.6949\n",
      "Epoch 7/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4639 - loss: 229.8502 - val_accuracy: 0.4932 - val_loss: 37.1307\n",
      "Epoch 8/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5368 - loss: 61.2114 - val_accuracy: 0.5135 - val_loss: 183.9699\n",
      "Epoch 9/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5090 - loss: 127.8313 - val_accuracy: 0.5541 - val_loss: 35.6148\n",
      "Epoch 10/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4894 - loss: 40.3533 - val_accuracy: 0.4392 - val_loss: 42.0248\n",
      "Epoch 11/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4870 - loss: 93.2253 - val_accuracy: 0.3986 - val_loss: 252.9102\n",
      "Epoch 12/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5318 - loss: 124.8261 - val_accuracy: 0.5000 - val_loss: 78.3710\n",
      "Epoch 13/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5031 - loss: 123.4539 - val_accuracy: 0.4527 - val_loss: 104.7577\n",
      "Epoch 14/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4649 - loss: 129.4010 - val_accuracy: 0.5135 - val_loss: 97.2663\n"
     ]
    }
   ],
   "source": [
    "# Train the model with validation data\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)  # Thresholding for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_Yc4Q0YULY8",
    "outputId": "d3546c63-1233-4cec-84da-cde7d69f7aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5475 - loss: 37.8463\n",
      "Test accuracy: 0.510869562625885\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "r0JwzzC3UJBz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5108695652173914\n",
      "Precision: 0.4811320754716981\n",
      "Recall: 0.5930232558139535\n",
      "F1-score: 0.5099431818181819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.44      0.49        98\n",
      "           1       0.48      0.59      0.53        86\n",
      "\n",
      "    accuracy                           0.51       184\n",
      "   macro avg       0.52      0.52      0.51       184\n",
      "weighted avg       0.52      0.51      0.51       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')  # Macro averaging for imbalanced classes (optional)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Additionally, you can get a more detailed classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2JHu9NcTqBg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
